{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up environment and import data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import sklearn.ensemble as ske\n",
    "\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['city' 'year' 'weekofyear' 'ndvi_ne' 'ndvi_nw' 'ndvi_se' 'ndvi_sw'\n",
      " 'Unnamed: 7' 'precipitation_amt_mm' 'reanalysis_air_temp_k'\n",
      " 'reanalysis_avg_temp_k' 'reanalysis_dew_point_temp_k'\n",
      " 'reanalysis_max_air_temp_k' 'reanalysis_min_air_temp_k'\n",
      " 'reanalysis_precip_amt_kg_per_m2' 'reanalysis_relative_humidity_percent'\n",
      " 'reanalysis_sat_precip_amt_mm' 'reanalysis_specific_humidity_g_per_kg'\n",
      " 'reanalysis_tdtr_k' 'station_avg_temp_c' 'station_diur_temp_rng_c'\n",
      " 'station_max_temp_c' 'station_min_temp_c' 'station_precip_mm'\n",
      " 'total_cases']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['ndvi_ne','ndvi_nw','ndvi_se','ndvi_sw']\n",
    "df = df.drop(cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['city' 'year' 'weekofyear' 'Unnamed: 7' 'precipitation_amt_mm'\n",
      " 'reanalysis_air_temp_k' 'reanalysis_avg_temp_k'\n",
      " 'reanalysis_dew_point_temp_k' 'reanalysis_max_air_temp_k'\n",
      " 'reanalysis_min_air_temp_k' 'reanalysis_precip_amt_kg_per_m2'\n",
      " 'reanalysis_relative_humidity_percent' 'reanalysis_sat_precip_amt_mm'\n",
      " 'reanalysis_specific_humidity_g_per_kg' 'reanalysis_tdtr_k'\n",
      " 'station_avg_temp_c' 'station_diur_temp_rng_c' 'station_max_temp_c'\n",
      " 'station_min_temp_c' 'station_precip_mm' 'total_cases']\n"
     ]
    }
   ],
   "source": [
    "df['city'] = df['city'].map({'sj': 1, 'iq': 2})\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(927, 21)\n",
      "(473, 21)\n"
     ]
    }
   ],
   "source": [
    "df_1 = df[df['city']==1]\n",
    "df_2 = df[df['city']==2]\n",
    "print(df_1.shape)\n",
    "print(df_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df.drop(['total_cases'],axis=1).values\n",
    "X_1 = df_1.drop(['total_cases'],axis=1)\n",
    "X_scaled_1 = preprocessing.scale(X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df.drop(['total_cases'],axis=1).values\n",
    "X_2 = df_2.drop(['total_cases'],axis=1)\n",
    "X_scaled_2 = preprocessing.scale(X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = df['total_cases'].values\n",
    "y_1 = df_1['total_cases']\n",
    "#y_scaled_1 = preprocessing.scale(y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = df['total_cases'].values\n",
    "y_2 = df_2['total_cases']\n",
    "#y_scaled_2 = preprocessing.scale(y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1,y_1,test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2,y_2,test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7295549182559786\n"
     ]
    }
   ],
   "source": [
    "clf_rf = ske.RandomForestRegressor(n_estimators=2000)\n",
    "clf_rf_1 = clf_rf.fit(X_train_1, y_train_1)\n",
    "print(clf_rf_1.score(X_test_1,y_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2560789520126242\n"
     ]
    }
   ],
   "source": [
    "clf_rf = ske.RandomForestRegressor(n_estimators=2000)\n",
    "clf_rf_2 = clf_rf.fit(X_train_2, y_train_2)\n",
    "print(clf_rf_2.score(X_test_2,y_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7256464905300692\n"
     ]
    }
   ],
   "source": [
    "clf_gb = ske.GradientBoostingRegressor(n_estimators=500)\n",
    "clf_gb_1 = clf_gb.fit(X_train_1, y_train_1)\n",
    "print(clf_gb_1.score(X_test_1,y_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.045481282631880116\n"
     ]
    }
   ],
   "source": [
    "clf_gb = ske.GradientBoostingRegressor(n_estimators=500)\n",
    "clf_gb_2 = clf_gb.fit(X_train_2, y_train_2)\n",
    "print(clf_gb_2.score(X_test_2,y_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "cols = ['ndvi_ne','ndvi_nw','ndvi_se','ndvi_sw']\n",
    "test = test.drop(cols,axis=1)\n",
    "test['city'] = test['city'].map({'sj': 1, 'iq': 2})\n",
    "test_1 = test[test['city']==1]\n",
    "test_2 = test[test['city']==2]\n",
    "\n",
    "\n",
    "imputer = Imputer()\n",
    "test_1 = imputer.fit_transform(test_1)\n",
    "test_2 = imputer.fit_transform(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260, 20)\n"
     ]
    }
   ],
   "source": [
    "print(test_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156, 20)\n"
     ]
    }
   ],
   "source": [
    "print(test_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.   5.   6.  12.   7.   9.   8.  15.  15.  15.  17.  19.  23.  51.\n",
      "  58.  78.  61.  69. 103. 101.  77.  65.  80.  63.  72.  41.  36.  47.\n",
      "  45.  31.  26.  23.  20.  22.  19.  20.  15.  16.  15.  14.  11.  10.\n",
      "   9.   9.   7.   8.   6.   5.   6.   5.   6.   7.   6.   5.   7.   6.\n",
      "  12.   7.   8.  11.   9.  17.  26.  25.  35.  60.  64.  64.  71.  83.\n",
      "  92.  53.  75.  72.  82.  89.  89.  74.  66.  48.  33.  61.  51.  30.\n",
      "  29.  29.  28. 308.  16.  15.  17.  15.  12.  14.  13.  11.  11.   8.\n",
      "   8.  11.   8.   7.   6.   6. 306.  16.   6.  14.  13.  32.  26.  32.\n",
      "  31.  28.  34.  41.  37.  39.  61.  88.  79. 104. 112. 111.  90.  85.\n",
      "  72.  77. 105.  74.  69.  42.  49.  28.  24.  22.  34.  28.  22.  19.\n",
      "  15.  14.  15.  15.  14.  12.  12.  10.  10.   7.   8.   5.   6.   7.\n",
      "   7.   6.  70.   7.   7.   6.  10.  16.  14.  32.  33.  33.  29.  35.\n",
      "  23.  42.  46.  89.  66. 107.  70.  71.  74.  53.  66.  78.  70.  63.\n",
      "  38.  53.  53. 273.  29.  27.  23.  25.  18.  20.  18.  13.  14.  15.\n",
      "  13.  10.  12.  10.  10.   6.   6.   6.   7.   6.   6.   7.   7.   8.\n",
      "   7. 285.  11.   8.  12.  16.  23.  22.  19.  18.  29.  35.  53.  55.\n",
      "  76.  69.  54.  66.  83.  86.  86.  83.  69.  72.  73.  92.  66.  49.\n",
      "  57.  31.  27.  65.  39.  87.  15.  47.  15.  14.  11.  11.  12.  10.\n",
      "   9.   8.   6.   6.   6.   8.   8.   5.]\n"
     ]
    }
   ],
   "source": [
    "predict_1 = clf_rf_1.predict(test_1)\n",
    "predict_1 = np.rint(predict_1)\n",
    "print(predict_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.  3.  5.  4.  4.  6.  6.  4.  6.  8.  5.  7. 11. 11. 14. 10. 13.  8.\n",
      " 11. 18. 13. 11. 16.  8. 12. 13.  9. 19. 14. 18. 19. 18. 20. 15. 20. 16.\n",
      " 13.  7.  9.  7.  6.  5.  4.  6.  7.  4.  5.  5.  3.  5.  4.  3.  3.  4.\n",
      "  4.  4.  3.  3.  5.  3.  4.  4.  4.  7.  6. 10.  8.  9.  9. 12. 12. 19.\n",
      " 11.  8.  8.  7. 17. 21. 10. 18. 17. 19. 18. 18. 15. 20. 19. 19. 12.  5.\n",
      "  5.  7.  4.  6.  7.  6.  5.  3.  6.  3.  4.  4.  5.  4.  6.  4.  5.  6.\n",
      "  5.  3.  4.  5.  6.  5.  4.  5.  8. 11. 10. 13.  9.  7. 11. 12. 10. 19.\n",
      "  9.  9.  8.  8. 17. 23. 20. 17. 23. 14. 16. 15. 16. 13.  8.  8.  7.  7.\n",
      "  6.  7.  6.  5.  6.  6.  5.  5.  3.  3.  4.  4.]\n"
     ]
    }
   ],
   "source": [
    "predict_2 = clf_rf_2.predict(test_2)\n",
    "predict_2 = np.rint(predict_2)\n",
    "print(predict_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"output1.csv\", predict_1, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"output2.csv\", predict_2, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**polynomial approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-15. -23.  -1.   6.   1.  -3.  -3.  13.   7.  -3.  -7.  -8.   1.   5.\n",
      "  20.  19.  35.  28.  59.  43.  25.  45.  24.  24.  19.  -1.   5.  24.\n",
      "  16.  11. -10. -26. -35. -28. -47.  30.  -4.  -3. -11. -10.  -9.  -2.\n",
      "  -5.  -1. -13. -25. -11. -26. -22. -15. -17. -27. -31. -39. -32.  -8.\n",
      " -13. -15. -13.   2.  10.   9.   5.  10.  15.   6.  11.  23.  28.  18.\n",
      "  20.  21.  20.  28.  38.  35.  18.  22.  12.  14.  13.  12.  -5.  -8.\n",
      " -13. -13.   6.  10.  -1.  -7.  12.  17.   1.  -2.   3.   9.  -7.  -4.\n",
      "  -6.  12. -16. -11.   2.   3. -15. -10.   0.  49.  18.  10.  18.   9.\n",
      "  15.  25.  26.  12.  15.  38.  28.  31.  64.  40.  37.  27.  27.  29.\n",
      "  39.  24.  15.  13.  17. -14. -26. -40. -17. -24. -50. -77.  -3. -17.\n",
      " -26. -25. -23. -28. -40. -40.  -9. -28.  -5. -34. -41. -43. -43. -50.\n",
      " -44. -50. -46. -13.  20. -22. -25.  53. -14. -17. -19. -25. -29.  -8.\n",
      " -12.  -4. -12.  25.  -3. -13.  16.  -7.  -6.  -5. -15. -14. -20. -17.\n",
      " -18. -20. -15. -42. -62. -37. -66. -74. -12. -32. -15. -26. -25. -38.\n",
      " -38. -40. -39. -49. -46. -25. -49. -51. -49. -45. -28. -53. -57. -43.\n",
      " -46. -48. -29. -27. -22. -26. -29. -31. -27. -26. -23. -13. -13. -21.\n",
      "  -8. -38. -14. -17.  -0.  -7. -15.   3. -10.  -1. -26.  -6. -25. -42.\n",
      " -52. -54. -69. -25. -17. -11. -26. -41. -19. -20. -24. -31.  -8. -27.\n",
      "   7. -45. -49. -59. -56. -58.   1. -11.   2. -27.   3.  -6.  25.  -1.\n",
      "  45.  13.  -1.   7.   3.  11.  27.   8.  16.   9.  -6.  18.  -2.  -6.\n",
      "  11.   1.  -5.   5. -14.  53.  42.  41.  48.  33.  33.  25.  29.  24.\n",
      "  22.  21.  19.  16.  20.   5.   5.  15.  12.  -6.  -0.  10.   1. -10.\n",
      "   0.  -8.  -5.  12.  -1.  -2.   5.  -0.   4.   9.   2.  13.  -7.  -3.\n",
      "  14.   2.  -4.  -4.   6.  10.  21.  27.  -3.  -0.   6.   5.   9.  -2.\n",
      "  -3.  47.  44.  37.  39.  38.  28.  38.  36.  28.  19.  20.  17.  21.\n",
      "   6.  21.  14.  13.  20.   7.   8.   8.  12.  -6.   4.  17.  -4.  13.\n",
      " -15. -10. -17. -10.   1.  42.   2.   7. -17.  13.  11.   5.  -3.   8.\n",
      "  -3.  14.  17.   0.  31.  11.  27.  10.   7.  10.  45.  38.  38.  43.\n",
      "  31.  43.  30.  29.  27.  25.  25.  26.  28.  18.  23.  23.  13.  30.\n",
      "   9.   4.  -6.   7.  21.  -9. -18.   7.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Create matrix and vectors\n",
    "\n",
    "# PolynomialFeatures (prepreprocessing)\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_ = poly.fit_transform(X)\n",
    "X_test_ = poly.fit_transform(X_test)\n",
    "\n",
    "lg = LinearRegression()\n",
    "\n",
    "# Fit\n",
    "lg.fit(X_, y)\n",
    "\n",
    "# Obtain coefficients\n",
    "#lg.coef_\n",
    "\n",
    "# Predict\n",
    "test = pd.read_csv('short_test.csv')\n",
    "test['city'] = test['city'].map({'sj': 1, 'iq': 2})\n",
    "test = test.dropna()\n",
    "test_ = poly.fit_transform(test)\n",
    "predictions = lg.predict(test_)\n",
    "#np.around(predictions)\n",
    "print(np.around(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"output.csv\", np.around(predictions), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
